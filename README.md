# Alex Sytsin
*Deep Learning Engineer*
---
<p align="left">
  <a href="mailto:aliaksandr.sytsin@gmail.com">aliaksandr.sytsin@gmail.com</a> ‚Ä¢
  <a href="https://www.linkedin.com/in/alexsytin/">LinkedIn</a> ‚Ä¢
  <a href="https://github.com/AlexSytsin/AlexSytsin">GitHub</a>
</p>

## üë§ About

Deep Learning Engineer with 3 years of commercial experience building and optimizing large-scale deep learning systems. Skilled in the end-to-end ML lifecycle: from data curation and processing to training state-of-the-art models and architecting high-throughput inference pipelines. Expert in Generative AI, NLP, and Speech Synthesis, with a proven track record of translating complex research into production-grade solutions that deliver tangible business value. Passionate about the rapid evolution of AI/ML and its real-world applications.

## üõ†Ô∏è Skills

| Category                  | Technologies & Concepts                                                                                                                              |
| ------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Programming & Core Tech** | Python, C++, SQL, Git, Bash, CI/CD, Docker                                                                                                           |
| **ML/DL Frameworks**      | PyTorch, TensorFlow, Hugging Face Transformers, vLLM, DeepSpeed, Accelerate                                                                          |
| **MLOps & Infrastructure**| NVIDIA Triton Inference Server, Apache Airflow, MLflow, Weights & Biases, Vertex AI, Hadoop, FastAPI, TensorBoard                                      |
| **Core Competencies**     | Multimodal Models (VAT, T2VA), Speech Synthesis (TTS), Voice Cloning, Performance Optimization, Distributed Training & Inference, NLP, CV, RL, ASR     |


## üíº Experience

### ML Research Intern @ Huawei
*April 2024 ‚Äì Present (1.7 years)*

*   Architected an end-to-end Video-Audio-Text (VAT) data captioning pipeline, integrating advanced audio-visual models that boosted training data quality and reduced multimodal captioning errors by **28%**.
*   Boosted inference throughput by **6.8x** and cut per-video latency by **33%** through optimized multi-GPU batching and advanced I/O management.
*   Engineered an LLM-based validation system for post-processing captions, automatically detecting hallucinations and resulting in a **31%** reduction in final captioning errors.
*   Fine-tuned Large Language Models for the video captioning module, improving the description acceptance rate by **19%** and deploying with vLLM.
*   Led the end-to-end training of a state-of-the-art T2VA model capable of generating high-fidelity video, outperforming the previous baseline by **12%** on key quality and temporal consistency metrics.

**Technologies:** PyTorch, vLLM, DeepSpeed, Accelerate, Transformers, Pandas, SQL, Docker

### ML Engineer Intern @ Yandex
*December 2022 ‚Äì April 2024 (1.5 years)*

*   Architected a next-generation TTS model by engineering a new neural codec and replacing the diffusion module with Flow Matching, fundamentally improving synthesis efficiency and quality.
*   Slashed model inference steps by **90%** (from 100 to 10) by implementing Flow Matching, achieving a **4.3x speedup** in voice generation without any loss in audio quality.
*   Deployed the production TTS model on NVIDIA Triton Inference Server, engineering a dynamic batching strategy that improved throughput by **3x** and reduced latency by **42%** under high load.
*   Boosted neural codec reconstruction accuracy by **6%**, enhancing the voice cloning quality for a video translation service with millions of active users.

**Technologies:** PyTorch, NVIDIA Triton Inference Server, Airflow, MLflow, Hadoop, YTsaurus, SQL, Docker, TensorBoard

## üéì Education

### Belarusian State University, Minsk
*Bachelor of Science, Information and Computer Science (2021 - 2025)*

**Relevant Coursework:**
*   *Stanford CS236: Deep Generative Models*
*   *Stanford CS336: Language Modeling from Scratch*

## üèÜ Awards & Achievements

*   **Winner (1st Place)** - The Hackathon: AI Era
*   **Gold Medal** - National Mathematical Olympiad (IMO Team Selection)

